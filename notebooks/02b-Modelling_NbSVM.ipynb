{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standard-worcester",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automotive-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from scipy import sparse\n",
    "\n",
    "from common import tokenize, tokenize_with_stopw, tokenize_and_lemma, eval_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-tablet",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "postal-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8) (153164, 8)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "test_y = pd.read_csv('../data/test_labels.csv')\n",
    "test_df = pd.concat([test_df, test_y.iloc[:,1:]], axis=1, sort=False)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-confidence",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pediatric-closing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_tracker = {}\n",
    "non_toxic_label = 'non_toxic'\n",
    "comment_col = 'comment_text'\n",
    "\n",
    "class_labels = train_df.columns.tolist()[2:]\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emotional-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-toxic class and fillna\n",
    "train_df[non_toxic_label] = 1 - train_df[class_labels].max(axis=1)\n",
    "train_df[comment_col] = train_df[comment_col].fillna('unknown')\n",
    "test_df[comment_col] = test_df[comment_col].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-tuning",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-rental",
   "metadata": {},
   "source": [
    "#### NB-SVM Model\n",
    "- Reference paper: https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf\n",
    "- Reference implementation: https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline\n",
    "- Quoted from the reference implementation\n",
    "        '''we use sklearn's logistic regression, rather than SVM,\n",
    "        although in practice the two are nearly identical\n",
    "        (sklearn uses the liblinear library behind the scenes)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-balance",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "normal-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdl(x, y, **kwargs):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: sparse matrix\n",
    "        vectorized train data\n",
    "    y: sparse matrix\n",
    "        vectorized train labels\n",
    "    kwargs:\n",
    "        parameters passed to LogisticRegression\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    m: fitted LogisticRegression model\n",
    "    r: sparse matrix of type float\n",
    "        log of \n",
    "        (probability of x given y=1) / (probability of x given y=0)\n",
    "    '''   \n",
    "    \n",
    "    def pr(x, y_i, y):\n",
    "        '''Compute Naive Bayes probability output'''\n",
    "        p = x[y==y_i].sum(0)\n",
    "        return (p+1) / ((y==y_i).sum()+1)\n",
    "    \n",
    "    y = y.values\n",
    "    r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
    "    m = LogisticRegression(**kwargs)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def get_pred_nbsvm(train_y, train_x,\n",
    "                   test_x,\n",
    "                   class_labels=class_labels,\n",
    "                   **kwargs):\n",
    "    '''Get predictions for each label at a time'''\n",
    "    # Initialize prediction output array\n",
    "    preds = np.zeros((test_x.shape[0], len(class_labels)))\n",
    "\n",
    "    # Get predictions for each label\n",
    "    for idx, label in enumerate(class_labels):\n",
    "        print('fit', label)\n",
    "        m, r = get_mdl(train_x, train_y[label], **kwargs)\n",
    "        preds[:, idx] = m.predict_proba(test_x.multiply(r))[:,1]\n",
    "    return preds\n",
    "\n",
    "def run_nbsvm(vectorizer,\n",
    "              train_df, test_df,\n",
    "              comment_col=comment_col,\n",
    "              class_labels=class_labels,\n",
    "              **kwargs):\n",
    "    '''Run 1 nbsvm prediction cycle'''\n",
    "    \n",
    "    # Transform data\n",
    "    train_x = vectorizer.fit_transform(train_df[comment_col])\n",
    "    test_x = vectorizer.transform(test_df[comment_col])\n",
    "    train_y = train_df[class_labels]\n",
    "    test_y = test_df[class_labels]\n",
    "    \n",
    "    # Get prediction and score\n",
    "    preds = get_pred_nbsvm(train_y, train_x,\n",
    "                           test_x,\n",
    "                           class_labels,\n",
    "                           **kwargs)\n",
    "    score = eval_pred(test_y, preds, class_labels)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-brooks",
   "metadata": {},
   "source": [
    "##### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gentle-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vectorizers\n",
    "cntvec = CountVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "                           min_df=3, max_df=0.9, strip_accents='unicode')\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "                        min_df=3, max_df=0.9, strip_accents='unicode',\n",
    "                        sublinear_tf=True)\n",
    "tfidf_stopw = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize_with_stopw,\n",
    "                              min_df=3, max_df=0.9, strip_accents='unicode',\n",
    "                              sublinear_tf=True)\n",
    "tfidf_lemma = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize_and_lemma,\n",
    "                              min_df=3, max_df=0.9, strip_accents='unicode',\n",
    "                              sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-hormone",
   "metadata": {},
   "source": [
    "##### 1.1 CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cultural-ranch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "fit severe_toxic\n",
      "fit obscene\n",
      "fit threat\n",
      "fit insult\n",
      "fit identity_hate\n",
      "Mean ROC-AUC: 0.9421376159074196\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit, predict and get scores\n",
    "score_cntvec = run_nbsvm(\n",
    "    cntvec, train_df, test_df,\n",
    "    comment_col=comment_col,\n",
    "    class_labels=class_labels,\n",
    "    C=4, dual=False,\n",
    "    max_iter=200,\n",
    "    random_state=123, n_jobs=-1)\n",
    "\n",
    "scores_tracker['nbsvm_cntvec'] = score_cntvec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-robertson",
   "metadata": {},
   "source": [
    "##### 1.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atmospheric-perry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "fit severe_toxic\n",
      "fit obscene\n",
      "fit threat\n",
      "fit insult\n",
      "fit identity_hate\n",
      "Mean ROC-AUC: 0.9762957516442285\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit, predict and get scores\n",
    "score_tfidf = run_nbsvm(\n",
    "    tfidf, train_df, test_df,\n",
    "    comment_col=comment_col,\n",
    "    class_labels=class_labels,\n",
    "    C=4, dual=False,\n",
    "    max_iter=200,\n",
    "    random_state=123, n_jobs=-1)\n",
    "scores_tracker['nbsvm_tfidf'] = score_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-shell",
   "metadata": {},
   "source": [
    "##### 1.3 TF-IDF with stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "loose-sector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "fit severe_toxic\n",
      "fit obscene\n",
      "fit threat\n",
      "fit insult\n",
      "fit identity_hate\n",
      "Mean ROC-AUC: 0.9737348660544357\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit, predict and get scores\n",
    "score_tfidf_stopw = run_nbsvm(\n",
    "    tfidf_stopw, train_df, test_df,\n",
    "    comment_col=comment_col,\n",
    "    class_labels=class_labels,\n",
    "    C=4, dual=False,\n",
    "    max_iter=200,\n",
    "    random_state=123, n_jobs=-1)\n",
    "scores_tracker['nbsvm_tfidf_stopw'] = score_tfidf_stopw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-density",
   "metadata": {},
   "source": [
    "##### 1.4 TF-IDF with lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "steady-brunei",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "fit severe_toxic\n",
      "fit obscene\n",
      "fit threat\n",
      "fit insult\n",
      "fit identity_hate\n",
      "Mean ROC-AUC: 0.9772775631141992\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit, predict and get scores\n",
    "score_tfidf_lemma = run_nbsvm(\n",
    "    tfidf_lemma, train_df, test_df,\n",
    "    comment_col=comment_col,\n",
    "    class_labels=class_labels,\n",
    "    C=4, dual=False,\n",
    "    max_iter=50,\n",
    "    random_state=123, n_jobs=-1)\n",
    "scores_tracker['nbsvm_tfidf_lemma'] = score_tfidf_lemma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
